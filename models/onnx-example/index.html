<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.0/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-KyZXEAg3QhqLMpG8r+8fhAXLRk2vvoC2f3B09zVXn8CA5QIVfZOJ3BCsw2P0p/We" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.5.0/font/bootstrap-icons.css">
    <link rel="stylesheet" href="/model.zoo/css/monokailight-syntax.css">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.0/dist/js/bootstrap.bundle.min.js" integrity="sha384-U1DAWAznBHeqEIlVSCgzq+c9gqGAJn5c/t99JyeKa9xxaYpSvHU5awsuZVVFIhvj" crossorigin="anonymous"></script>
    
    
    <title>Simula Model Zoo | ONNX Example</title>
</head>
<body>


<nav class="navbar navbar-expand-md navbar-light bg-light py-4">  
    <div class="container">
        <div class="navbar-collapse collapse w-100 order-1 order-md-0 dual-collapse2">
            <a class="navbar-brand" href="https://steffen.maeland.gitlab.io/model.zoo/">
                <img src="https://steffen.maeland.gitlab.io/model.zoo/images/simula_main_small_RGB.png " alt="" height="42" class="d-inline-block" style="padding-bottom: 14px;">
                Model Zoo
                </a>
            <ul class="navbar-nav me-auto">
                <h5 style="margin-right: 4em">BETA</h5>
                
                    <li class="nav-item">
                        <a class="nav-link " href="/model.zoo/"> Home</a>
                    </li>
                
                    <li class="nav-item">
                        <a class="nav-link " href="/model.zoo/categories/"> Categories</a>
                    </li>
                
                    <li class="nav-item">
                        <a class="nav-link " href="/model.zoo/tags/"> Tags</a>
                    </li>
                
                    <li class="nav-item">
                        <a class="nav-link " href="/model.zoo/docs/"> How-to</a>
                    </li>
                
            </ul>
        </div>
        
        <div class="navbar-collapse collapse w-100 order-3 dual-collapse2">
            <ul class="navbar-nav ms-auto">
                <li class="nav-item">
                    <a class="btn btn-success" href="#">Submit a model</a>
                </li>
            </ul>
        </div>
    </div>
</nav>
<div id="content">






<div class='container'>
    <div class="row mt-5">
        <h1>ONNX Example</h1>
            <br>
            <p class="lead">Example using ONNX for saving models in a framework-independent format</p>
        <div class="col-sm-9">
            
            <div class="card bg-light">
                <div class="card-body">
                    <h5>Download</h5>
                    <ul class="nav nav-tabs nav-fill " id="myTab" role="tablist">
                        <li class="nav-item" role="presentation">
                          <button class="nav-link active" id="home-tab" data-bs-toggle="tab" data-bs-target="#files" type="button" role="tab">Files</button>
                        </li>
                        <li class="nav-item" role="presentation">
                          <button class="nav-link" id="profile-tab" data-bs-toggle="tab" data-bs-target="#image" type="button" role="tab">Docker image</button>
                        </li>
                        <li class="nav-item" role="presentation">
                            <button class="nav-link" id="profile-tab" data-bs-toggle="tab" data-bs-target="#notebook" type="button" role="tab">Notebook</button>
                          </li>
                      </ul>
                      <div class="tab-content" id="myTabContent">
                        <div class="tab-pane fade show active" id="files" role="tabpanel" aria-labelledby="home-tab">
                            <br>
                            <i>If the download does not start automatically, right-click and select "Save Link As..."</i>
                            <br><br>
                            
                                <a class="btn btn-primary" href="https://raw.githubusercontent.com/smaeland/model-zoo-onnx-mnist-example/master/requirements.txt" download><i class="bi bi-arrow-down"></i> requirements.txt</a>
                            
                            
                                <a class="btn btn-primary" href="https://github.com/smaeland/model-zoo-onnx-mnist-example/blob/master/onnx-cnn-model.onnx?raw=true" download><i class="bi bi-arrow-down"></i> onnx-cnn-model.onnx</a>
                            
                            <br><br>
                            
                            <i>Or download using <code>wget</code>:</i>
                            <br>
                            <div class="highlight">
                                <pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">wget https://raw.githubusercontent.com/smaeland/model-zoo-onnx-mnist-example/master/requirements.txt
wget https://github.com/smaeland/model-zoo-onnx-mnist-example/blob/master/onnx-cnn-model.onnx?raw=true</code></pre>

                            </div>
                            
                        </div>
                        <div class="tab-pane fade" id="image" role="tabpanel">
                            <br>
                            
                            <a class="btn btn-primary disabled" href="#"><i>No image provided</i></a>
                            
                        </div>
                        <div class="tab-pane fade" id="notebook" role="tabpanel">
                            <br>
                            
                            <a class="btn btn btn-primary disabled" href="#"><i>No notebook provided</i></a>
                            
                        </div>
                      </div>
                </div>
            </div>
            <br>
            <p><a href="onnx.ai">Open Neural Network Exchange (ONNX)</a> is an initiative to provide a
unified format for saving (and running) ML models. It works with PyTorch and
TensorFlow, but also non-neural-network frameworks such as Scikit-Learn and
XGBoost. Here we train a model in PyTorch, and use ONNX to i) run it in
the ONNX runtime, which does not require PyTorch at all, and ii) convert
the model into TensorFlow format.</p>
<h3 id="dependencies">Dependencies</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">wget https://raw.githubusercontent.com/smaeland/model-zoo-onnx-mnist-example/master/requirements.txt
pip install -r requirements.txt
</code></pre></div><h3 id="download-the-model">Download the model</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">wget https://github.com/smaeland/model-zoo-onnx-mnist-example/blob/master/onnx-cnn-model.onnx?raw=true
</code></pre></div><h3 id="data">Data</h3>
<p>The model is trained on the
<a href="https://github.com/zalandoresearch/fashion-mnist">Fashion-MNIST</a> dataset.
Start by downloading it:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz
wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz
wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz
wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz
</code></pre></div><p>Note that these files are gzipped, and does not in fact contain image files,
but can be converted to a more typical format by</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">gzip</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">load_mnist</span><span class="p">(</span><span class="n">data_file</span><span class="p">,</span> <span class="n">label_file</span><span class="p">):</span>

    <span class="k">with</span> <span class="n">gzip</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">label_file</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">lbpath</span><span class="p">:</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">frombuffer</span><span class="p">(</span><span class="n">lbpath</span><span class="o">.</span><span class="n">read</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">gzip</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">data_file</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">imgpath</span><span class="p">:</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">frombuffer</span><span class="p">(</span><span class="n">imgpath</span><span class="o">.</span><span class="n">read</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">,</span><span class="n">offset</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">),</span> <span class="mi">784</span><span class="p">)</span>

    <span class="n">images</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">newshape</span><span class="o">=</span><span class="p">(</span><span class="n">images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span>

<span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">load_mnist</span><span class="p">(</span><span class="s1">&#39;t10k-images-idx3-ubyte.gz&#39;</span><span class="p">,</span> <span class="s1">&#39;t10k-labels-idx1-ubyte.gz&#39;</span><span class="p">)</span>
<span class="n">class_names</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;T-shirt/top&#39;</span><span class="p">,</span> <span class="s1">&#39;Trouser&#39;</span><span class="p">,</span> <span class="s1">&#39;Pullover&#39;</span><span class="p">,</span> <span class="s1">&#39;Dress&#39;</span><span class="p">,</span> <span class="s1">&#39;Coat&#39;</span><span class="p">,</span>
    <span class="s1">&#39;Sandal&#39;</span><span class="p">,</span> <span class="s1">&#39;Shirt&#39;</span><span class="p">,</span> <span class="s1">&#39;Sneaker&#39;</span><span class="p">,</span> <span class="s1">&#39;Bag&#39;</span><span class="p">,</span> <span class="s1">&#39;Ankle boot&#39;</span>
<span class="p">]</span>
</code></pre></div><p>Preprocessing involves only scaling the pixel values.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">preprocess</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">data</span> <span class="o">/</span> <span class="mf">255.</span>

<span class="n">x_test</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1"># (10000, 1, 28, 28)</span>
</code></pre></div><h3 id="predict-using-the-onnx-runtime">Predict using the ONNX runtime</h3>
<p>The ONNX runtime differs slightly from the usual <code>model(x_test)</code> or
<code>model.predict(x_test)</code> since one needs to be more verbose about the inputs,
but is optimised for fast inference. Create an <code>InferenceSession</code> and identify
the input name and shape:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">onnxruntime</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">onnxruntime</span><span class="o">.</span><span class="n">InferenceSession</span><span class="p">(</span><span class="s1">&#39;onnx-cnn-model.onnx&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

<span class="n">input_node</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">input_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">input_node</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
<span class="n">input_name</span> <span class="o">=</span> <span class="n">input_node</span><span class="o">.</span><span class="n">name</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;input name: </span><span class="si">{</span><span class="n">input_name</span><span class="si">}</span><span class="s1">, shape: </span><span class="si">{</span><span class="n">input_shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="k">assert</span> <span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">==</span> <span class="n">input_shape</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;x_test.shape: </span><span class="si">{</span><span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1"> != input_shape: </span><span class="si">{</span><span class="n">input_shape</span><span class="si">}</span><span class="s1">&#39;</span>
</code></pre></div><p>Note that to run the inference session, the input data needs to be of the
correct type, in this case <code>float32</code>. Unlike other frameworks, ONNX does not
convert this automatically.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</code></pre></div><p>Now we can predict on the test set and compute the accuracy:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="n">preds_onecold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy:&#39;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">preds_onecold</span><span class="p">))</span>
<span class="c1"># Accuracy: 0.8957</span>
</code></pre></div><h3 id="convert-to-a-tensorflow-model">Convert to a TensorFlow model</h3>
<p>As mentioned, there are two way of going about this:</p>
<h4 id="convert-directly-to-a-new-save-file-on-the-command-line">Convert directly to a new save file, on the command line</h4>
<p>The <code>onnx-tf</code> package provides a command line tool that takes an ONNX save file
as input, and outputs a TensorFlow model directory:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">onnx-tf convert --infile onnx-cnn-model.onnx --outdir tf-model-converted-from-onnx
</code></pre></div><p>The output is in SavedModel format (which is <em>not</em> the same as what Keras uses),
and must be loaded accordingly:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">saved_model</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;tf-model-converted-from-onnx&#39;</span><span class="p">)</span>

<span class="c1"># Get the input shape</span>
<span class="n">input_spec</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">signatures</span><span class="p">[</span><span class="s1">&#39;serving_default&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">structured_input_signature</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;input&#39;</span><span class="p">]</span>
<span class="n">input_shape</span> <span class="o">=</span> <span class="n">input_spec</span><span class="o">.</span><span class="n">shape</span>
<span class="k">assert</span> <span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">==</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="sa">f</span><span class="s1">&#39;x_test.shape[1:]: </span><span class="si">{</span><span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="si">}</span><span class="s1"> != input_shape[1:]: </span><span class="si">{</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="si">}</span><span class="s1">&#39;</span>

<span class="c1"># Get the output name </span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">signatures</span><span class="p">[</span><span class="s1">&#39;serving_default&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">structured_outputs</span>
<span class="n">output_name</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">keys</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>   
</code></pre></div><p>With this in place, we can run inference and compute the accuracy again:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">infer</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">signatures</span><span class="p">[</span><span class="s1">&#39;serving_default&#39;</span><span class="p">]</span>
    
<span class="n">preds</span> <span class="o">=</span> <span class="n">infer</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">x_test</span><span class="p">))[</span><span class="n">output_name</span><span class="p">]</span>

<span class="n">preds_onecold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy:&#39;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">preds_onecold</span><span class="p">))</span>
<span class="c1"># Accuracy: 0.8957</span>
</code></pre></div><h4 id="convert-on-the-fly">Convert on the fly</h4>
<p>Lastly, we can load the ONNX file and convert it to TensorFlow inside a script,
which is rather straight-forward.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python">
<span class="n">onnx_model</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;onnx-cnn-model.onnx&#39;</span><span class="p">)</span>
<span class="n">tf_model</span> <span class="o">=</span> <span class="n">prepare</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>

<span class="n">preds</span> <span class="o">=</span> <span class="n">tf_model</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span><span class="o">.</span><span class="n">output</span>

<span class="n">preds_onecold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy:&#39;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">preds_onecold</span><span class="p">))</span>
<span class="c1"># Accuracy: 0.8957</span>
</code></pre></div>
        </div>
        <div class="col-sm-3">
            




<div class="card">
    <div class="card-header">
        <h5>Metadata</h5>
    </div>
    <div class="card-body">
        <p class="card-text">
            <span class="bi bi-calendar-date"></span>
            <time datetime="2021-09-08"> Published Sep 8, 2021</time>
            <br>
                <div class="d-grid gap-2">
                
                    <a class="btn btn-primary" href="https://github.com/smaeland/model-zoo-onnx-mnist-example"><i class="bi bi-code-slash"></i> Code repository</a>
                
            </div>
            <br>
            <h5>Categories</h5>
            


    <span class="btn btn-sm btn-outline-primary tag-btn"><i class="bi bi-folder"></i> Examples</span>

            <br><br>
            <h5>Tags</h5>
            


    <span class="btn btn-sm btn-outline-success tag-btn"><i class="bi bi-tag"></i> ONNX</span>

    <span class="btn btn-sm btn-outline-success tag-btn"><i class="bi bi-tag"></i> Fashion-MNIST</span>

        </p>
    </div>
</div>



        </div>
    </div>


</div>




        </div>
</body>
</html>
